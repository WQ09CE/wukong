# Ruyi Jingu Bang Protocol (如意金箍棒协议)

## Philosophy (理念)

> **大可顶天立地，小可藏于耳内。**
> 信息亦如金箍棒，可伸可缩，随需而变。

如意金箍棒是悟空的神兵利器，可随心意变大变小。在上下文管理中，金箍棒协议让信息也能"随意伸缩"：
- 上下文充足时，展开详细信息
- 上下文紧张时，压缩成核心要点
- 关键信息通过"锚点"永不丢失

## The Three Forms (三态)

### 🔸 缩形态 (Compact Form)

**适用场景**:
- 新分身启动，需要快速了解背景
- 上下文使用 > 75%
- 跨会话信息传递

**字数限制**: < 500 字

**格式模板**:
```markdown
## 🔸 缩形态上下文

【任务】{一句话描述目标}

【已决策】
- {决策1}: {选择} (原因: {简要原因})
- {决策2}: {选择}

【约束】
- {必须遵守的规则1}
- {必须遵守的规则2}

【当前进度】
- 已完成: {完成项}
- 进行中: {当前任务}
- 待处理: {下一步}

【锚点引用】
- 见 [D001], [C002], [I003]
```

---

### 🔹 常形态 (Normal Form)

**适用场景**:
- 正常工作过程
- 分身之间的标准信息传递
- 上下文使用 50-75%

**字数限制**: 500 - 2000 字

**格式模板**:
```markdown
## 🔹 常形态上下文

### 任务背景
{2-3 句话描述背景和目标}

### 已完成工作
| 阶段 | 内容 | 产出 |
|------|------|------|
| 需求 | {描述} | requirements.md |
| 设计 | {描述} | design.md |
| 实现 | {描述} | {files} |

### 关键决策
| ID | 决策 | 选择 | 原因 |
|----|------|------|------|
| D001 | {决策描述} | {选择} | {原因} |

### 当前焦点
{详细描述当前正在做的事情，包括：}
- 目标
- 方法
- 进展
- 问题

### 接口约定
```python
# 关键接口签名
{interface definitions}
```

### 注意事项
- {caveat 1}
- {caveat 2}

### 锚点索引
{列出相关锚点 ID}
```

---

### 🔶 巨形态 (Expanded Form)

**适用场景**:
- 需要完整历史上下文
- 调试复杂问题
- 上下文使用 < 50%

**字数限制**: 无限制（完整内容）

**存储位置**: `.wukong/context/session-{id}/expanded.md`

**格式模板**:
```markdown
## 🔶 巨形态上下文

### 完整会话历史
{按时间顺序记录所有重要交互}

### 所有决策及讨论
{包含决策过程、考虑的替代方案}

### 完整代码变更
{所有文件变更的详细记录}

### 问题与解决
{遇到的所有问题及解决过程}

### 用户偏好记录
{从对话中提取的用户偏好}

### 完整锚点列表
{所有锚点的详细定义}
```

---

## Anchor System (锚点系统)

> **锚点是不可压缩的关键信息**，无论金箍棒如何缩小，锚点始终保留。

### 锚点类型

| 类型 | 前缀 | 用途 | 示例 |
|------|------|------|------|
| 决策 | D | 架构/技术决策 | [D001] 使用 Ollama 而非 OpenAI |
| 约束 | C | 必须遵守的规则 | [C001] 所有输出必须脱敏 |
| 接口 | I | 关键接口定义 | [I001] Agent.review() -> ReviewResult |
| 问题 | P | 已知问题/陷阱 | [P001] FFmpeg 在某格式下泄漏内存 |
| 偏好 | U | 用户偏好 | [U001] 用户偏好简洁回复 |

### 锚点格式

```markdown
## [D001] 使用 Ollama 作为本地 LLM

**时间**: 2024-01-15
**背景**: 需要选择代码审查的 LLM 后端
**选项**:
- OpenAI API (强但贵)
- Ollama 本地 (免费但需部署)
- Claude API (强但有合规考虑)
**决定**: Ollama
**原因**: 成本低、数据本地化、隐私合规
**影响**: 需要维护 Ollama 容器
```

### 锚点存储

```
.wukong/context/
└── anchors.md    # 所有锚点的集中存储
```

### 锚点引用

在任何形态中，通过 `[D001]` 格式引用锚点：

```markdown
根据 [D001]，我们使用 Ollama 作为 LLM 后端。
考虑到 [C001] 的脱敏要求，需要在返回前调用 Sanitizer。
```

---

## Form Switching (形态切换)

### 自动切换规则

```
上下文使用监测:
├── < 50%  → 🔶 巨形态 (完整信息)
├── 50-75% → 🔹 常形态 (结构化压缩)
├── 75-90% → 🔸 缩形态 (核心摘要)
└── > 90%  → 触发"存档+重启"协议
```

### 存档+重启协议

当上下文接近满时：

```
1. 自动保存
   ├── 生成 expanded.md (完整历史)
   ├── 生成 normal.md (结构化摘要)
   └── 生成 compact.md (核心要点)

2. 通知用户
   "上下文接近上限，已自动存档。
    你可以：
    - 继续当前会话（我会使用压缩上下文）
    - 开始新会话（说'继续{任务名}'，我会加载存档）"

3. 如果继续
   └── 使用 compact.md 作为起点
       └── 需要详情时 Read normal.md 或 expanded.md
```

### 手动切换

用户可以主动请求切换：

| 用户说 | 动作 |
|--------|------|
| "详细说说" | 切换到巨形态 |
| "简要概括" | 切换到缩形态 |
| "存档一下" | 执行存档协议 |
| "加载上下文" | 读取最近存档 |

---

## Context Directory Structure (上下文目录结构)

```
.wukong/context/
├── anchors.md              # 全局锚点索引
├── current/                # 当前会话
│   ├── compact.md          # 缩形态
│   ├── normal.md           # 常形态
│   └── expanded.md         # 巨形态
├── sessions/               # 历史会话存档
│   ├── 2024-01-15-code-review-agent/
│   │   ├── compact.md
│   │   ├── normal.md
│   │   └── expanded.md
│   └── 2024-01-16-ruyi-protocol/
│       └── ...
└── templates/              # 模板
    ├── compact-template.md
    ├── normal-template.md
    └── anchor-template.md
```

---

## Integration with Avatars (与分身系统集成)

### 召唤分身时的上下文传递

```python
# 标准召唤模式
Task(
    subagent_type="general-purpose",
    prompt=f"""
## 🔸 缩形态上下文
{read_compact_context()}

## 相关锚点
{get_relevant_anchors(task_type)}

## 你的任务
{task_description}

## 注意
如需更多上下文，可 Read(".wukong/context/current/normal.md")
"""
)
```

### 分身返回时的上下文更新

```
分身完成任务后:
├── 提取新决策 → 创建锚点 [Dxxx]
├── 提取新约束 → 创建锚点 [Cxxx]
├── 提取新接口 → 创建锚点 [Ixxx]
├── 更新 compact.md
└── 追加到 expanded.md
```

---

## Best Practices (最佳实践)

### 1. 锚点命名

```
✅ 好的锚点:
[D001] 选择 FastAPI 作为后端框架
[C003] PR 描述不得包含代码内容

❌ 差的锚点:
[D001] 框架决策  (太模糊)
[C003] 规则      (无意义)
```

### 2. 压缩原则

```
压缩时保留:
├── 决策结论 (不是讨论过程)
├── 接口签名 (不是实现细节)
├── 约束规则 (不是背景解释)
└── 当前状态 (不是历史过程)

压缩时丢弃:
├── 探索性讨论
├── 已否决的方案
├── 临时调试信息
└── 重复的确认对话
```

### 3. 形态选择

```
分身启动 → 缩形态 (快速启动)
分身遇到问题 → 读取常形态
分身需要调试 → 读取巨形态
分身完成 → 更新所有形态
```

---

## Commands (命令)

| 命令 | 描述 |
|------|------|
| `存档` | 保存当前上下文到 sessions/ |
| `加载 {session-name}` | 加载历史会话 |
| `锚点` | 显示所有锚点 |
| `压缩` | 强制切换到缩形态 |
| `展开` | 强制切换到巨形态 |

---

## Example: Using Ruyi Protocol (示例)

### 场景：长对话后召唤新分身

```
本体检测: 上下文使用 70%

本体: 生成缩形态上下文...

召唤斗战胜佛:
"""
## 🔸 缩形态上下文

【任务】实现 Code Review Agent 的脱敏模块

【已决策】
- [D001] 使用 Ollama 作为本地 LLM
- [D002] 双层架构：Cloud + Local Container
- [D003] 使用正则 + 规则混合脱敏

【约束】
- [C001] 所有输出必须脱敏
- [C002] Git Token 只在容器内使用

【当前进度】
- 已完成: credentials.py, tools.py
- 进行中: sanitizer.py
- 待处理: agent.py, server.py

【锚点引用】
- 接口: [I001] Sanitizer.sanitize(data) -> Any
- 问题: [P001] 注意递归脱敏嵌套结构

## 你的任务
实现 sanitizer.py，遵循 [I001] 接口定义。

## 注意
如需更多上下文: Read(".wukong/context/current/normal.md")
"""
```

这样，新分身只需 ~300 字就能快速了解背景，需要时再读取更多。
